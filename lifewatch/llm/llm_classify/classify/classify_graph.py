"""
åŠŸèƒ½æè¿°: å®ç°åˆ†ç±»çš„langgraph
å¾…å®ç°å†…å®¹: åˆ†ç±»ç»“æœçš„éªŒè¯åŠŸèƒ½
date : 2025.12.17 
"""
# Date: 2025/12/17
from lifewatch.llm.llm_classify.schemas.classify_shemas import classifyState,Goal,AppInFo,classifyStateLogitems
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import SystemMessage, HumanMessage,AIMessage
from lifewatch.llm.llm_classify.utils import (
    format_goals_for_prompt, 
    format_category_tree_for_prompt,
    format_log_items_table,
    create_ChatTongyiModel,
    split_by_purpose,
    split_by_duration,
    parse_classification_result,
    extract_json_from_response,
    parse_token_usage,
    test_for_llm_class_state
    )
import json
import logging
from langgraph.types import Send,RetryPolicy
from langgraph.store.memory import InMemoryStore

import uuid
MAX_LOG_ITEMS = 15
MAX_TITLE_ITEMS = 5
SPLIT_DURATION = 10*60 # 20min
TEST_FLAG = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ClassifyGraph:
    def __init__(self, goal: list, category_tree: dict):
        """
        åˆå§‹åŒ–åˆ†ç±»å›¾
        
        Args:
            goal: ç”¨æˆ·ç›®æ ‡åˆ—è¡¨
            category_tree: åˆ†ç±»æ ‘å­—å…¸
        """
        self.goal = goal
        self.category_tree = category_tree
        self.chat_model = create_ChatTongyiModel()
        self.store = InMemoryStore()
        self.bulit_graph()

    def recode_tokens_usage(self,node_name,tokens_usage):
        name_space = ("tokens_usage",node_name)
        self.store.put(name_space,str(uuid.uuid4()),tokens_usage) # ç”Ÿæˆstr(uuid.uuid4())å”¯ä¸€keyï¼Œé¿å…å€¼è¢«è¦†ç›–
    
    def get_total_tokens_usage(self) -> dict:
        """
        è·å–æ€» token ä½¿ç”¨ç»Ÿè®¡
        """
        total = {
            'input_tokens': 0,
            'output_tokens': 0,
            'total_tokens': 0,
            'search_count': 0
        }
        
        # è·å–æ‰€æœ‰ tokens_usage å‘½åç©ºé—´
        namespaces = self.store.list_namespaces(prefix=("tokens_usage",))
        
        for namespace in namespaces:
            # æœç´¢è¯¥å‘½åç©ºé—´ä¸‹çš„æ‰€æœ‰è®°å½•
            items = self.store.search(namespace)
            for item in items:
                usage = item.value
                total['input_tokens'] += usage.get('input_tokens', 0)
                total['output_tokens'] += usage.get('output_tokens', 0)
                total['total_tokens'] += usage.get('total_tokens', 0)
                total['search_count'] += usage.get('search_count', 0)
        
        return total

    
    def bulit_graph(self):
        
        graph = StateGraph(classifyState)
        graph.add_node("get_app_description",self.get_app_description)
        graph.add_node("single_classify",self.single_classify,retry_policy=RetryPolicy(max_attempts=3))
        graph.add_node("multi_classify",self.multi_classify) # ç©ºèŠ‚ç‚¹
        graph.add_node("multi_classify_long",self.multi_classify_long,retry_policy=RetryPolicy(max_attempts=3))  # é•¿æ—¶é—´å¤šç”¨é€”åˆ†ç±»
        graph.add_node("multi_classify_short",self.multi_classify_short,retry_policy=RetryPolicy(max_attempts=3)) # çŸ­æ—¶é—´å¤šç”¨é€”åˆ†ç±»
        graph.add_node("get_titles",self.get_titles)

        graph.add_edge(START,"get_app_description")
        graph.add_conditional_edges("get_app_description",self.router_by_multi_purpose) # -> single_classify | -> multi_classify
        # å•ç”¨é€”åˆ†ç±»
        graph.add_edge("single_classify",END)
        # å¤šç”¨é€”åˆ†ç±»
        graph.add_conditional_edges("multi_classify",self.router_by_duration_for_multi) # ->multi_classify_short | -> get_titles
        graph.add_edge("multi_classify_short",END)
        graph.add_edge("get_titles","multi_classify_long")
        graph.add_edge("multi_classify_long",END)
        # çŸ­æ—¶é—´åˆ†ç±»
        # checkpointer = InMemorySaver()  
        self.app = graph.compile(store=self.store)
    def classify(self, state: classifyState) -> dict:
        """
        æ‰§è¡Œåˆ†ç±»ä»»åŠ¡çš„å…¥å£æ–¹æ³•
        
        Args:
            state: classifyState å¯¹è±¡ï¼ŒåŒ…å«å¾…åˆ†ç±»çš„æ•°æ®
            
        Returns:
            dict: åŒ…å« result_items å’Œ tokens_usage çš„å­—å…¸
        """
        # æ‰§è¡Œåˆ†ç±»
        output = self._classify_internal(state)
        
        # è·å– token ä½¿ç”¨ç»Ÿè®¡
        tokens_usage = self.get_total_tokens_usage()
        print(tokens_usage)
        return {
            "result_items": output.get("result_items"),
            "tokens_usage": tokens_usage
        }
    
    def _classify_internal(self, state: classifyState) -> dict:
        """
        å†…éƒ¨åˆ†ç±»å®ç°ï¼Œè°ƒç”¨ LangGraph
        
        Args:
            state: classifyState å¯¹è±¡ï¼ŒåŒ…å«å¾…åˆ†ç±»çš„æ•°æ®
            
        Returns:
            dict: LangGraph è¿”å›çš„åŸå§‹ç»“æœ
        """
        config = {"configurable": {"thread_id": f"thread-{uuid.uuid4()}"}}
        output = self.app.invoke(state, config)
        return output
    
    # node 1 è·å–æ‰€æœ‰appçš„æè¿°
    def get_app_description(self,state: classifyState) -> classifyState:
        """
        è·å–æ‰€æœ‰æ²¡æœ‰æè¿°çš„ app çš„æè¿°ä¿¡æ¯ï¼ˆä½¿ç”¨ for å¾ªç¯é¡ºåºæ‰§è¡Œï¼‰
        
        Args:
            state: classifyState å¯¹è±¡
            
        Returns:
            classifyState: æ›´æ–°äº† app_registry çš„çŠ¶æ€
        """
        # 1. æ‰¾å‡ºæ‰€æœ‰æ²¡æœ‰æè¿°çš„ app
        app_to_search = []
        for app, app_info in state.app_registry.items():
            if app_info.description is None or app_info.description == "":
                # è·å–ä¸€ä¸ª title æ ·æœ¬ç”¨äºè¾…åŠ©è¯†åˆ«
                title_sample = app_info.titles[0] if app_info.titles else ""
                app_to_search.append((app, title_sample))
        
        if not app_to_search:
            logger.info("æ‰€æœ‰ app éƒ½å·²æœ‰æè¿°ï¼Œè·³è¿‡æœç´¢")
            return {}
        
        logger.info(f"éœ€è¦æœç´¢æè¿°çš„ app: {[app for app, _ in app_to_search]}")
        
        # 2. é¡ºåºæœç´¢æ¯ä¸ª app çš„æè¿°
        app_descriptions = {}  # app_name -> description
        
        system_message = SystemMessage(content="""
        ä½ æ˜¯ä¸€ä¸ªè½¯ä»¶ç¨‹åºè¯†åˆ«ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯é€šè¿‡ web æœç´¢è¯†åˆ«è½¯ä»¶åº”ç”¨ç¨‹åºï¼Œå¹¶æä¾›å‡†ç¡®ã€ç²¾ç‚¼çš„æè¿°ã€‚
        **è¾“å…¥è¯´æ˜ï¼š**
        - è¾“å…¥è½¯ä»¶åç§°æˆ–ç¨‹åºåç§°ä¸çª—å£title
        **è¾“å‡ºè¦æ±‚ï¼š**
        - è½¯ä»¶æè¿°(ä¸è¶…è¿‡20è¯):ä»¥webæœç´¢ä¸ºä¸»,titleä¿¡æ¯ä¸ºè¾…
        - è¿”å›è½¯ä»¶æè¿°
        - å¦‚æœæœç´¢åä»æ— æ³•ç¡®å®šï¼Œè¿”å› None
        """)
        
        for app, title in app_to_search:
            try:
                user_message = HumanMessage(content=f"""è½¯ä»¶åç§°:{app} title:{title}""")
                messages = [system_message, user_message]
                
                result = self.chat_model.invoke(messages)
                self.recode_tokens_usage("app_descriptions",parse_token_usage(result))
                # è®°å½• token ä½¿ç”¨åˆ°å…¨å±€åˆ—è¡¨
                # record_token_usage("get_app_description", result)
                
                # æå–æè¿°
                app_descriptions[app] = result.content
                logger.info(f"å·²è·å– {app} çš„æè¿°: {result.content[:50]}...")
                
            except Exception as e:
                logger.error(f"æœç´¢ {app} æè¿°å¤±è´¥: {e}")
                app_descriptions[app] = None
        
        
        # 3. ç›´æ¥æ›´æ–° state.app_registry
        for app_name, description in app_descriptions.items():
            if app_name in state.app_registry:
                state.app_registry[app_name].description = description
        
        # è¿”å›æ›´æ–°åçš„çŠ¶æ€
        return {
            "app_registry": state.app_registry
        }

    # router 1 
    # @test_for_llm_class_state(TEST_FLAG)
    def router_by_multi_purpose(self,state: classifyState):
        """
        è½¯ä»¶åˆ†ç±»è·¯ç”±,å•ç”¨é€”å’Œå¤šç”¨é€”åˆ†å¼€å¤„ç†
        """
        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œç›´æ¥ç»“æŸ
        if not state.log_items:
            logger.info("log_items ä¸ºç©ºï¼Œè·³è¿‡åˆ†ç±»")
            return END
        
        log_dict = split_by_purpose(state)
        log_items_for_single = log_dict.get("log_items_for_single", [])
        log_items_for_multi = log_dict.get("log_items_for_multi", [])
        
        # åˆ›å»ºä¸­é—´ç§æœ‰çŠ¶æ€
        log_items_state = classifyStateLogitems(
            log_items_for_single=log_items_for_single if log_items_for_single else None,
            log_items_for_multi=log_items_for_multi if log_items_for_multi else None,
            private_app_registry=state.app_registry
        )
        
        send_list = []
        if not log_items_for_single:
            logger.info("log_items_for_single ä¸ºç©º, æ— å•ç”¨é€”æ•°æ®")
        else:
            send_list.append(Send("single_classify", log_items_state))
        if not log_items_for_multi:
            logger.info("log_items_for_multi ä¸ºç©º, æ— å¤šç”¨é€”æ•°æ®")
        else:
            send_list.append(Send("multi_classify", log_items_state))
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•ä»»åŠ¡è¦å‘é€ï¼Œè¿”å› END
        if not send_list:
            logger.info("æ²¡æœ‰æ•°æ®éœ€è¦åˆ†ç±»ï¼Œç›´æ¥ç»“æŸ")
            return END
        
        return send_list
    
    # node superstape2: å•ç”¨é€”åˆ†ç±» -> result_items
    # @test_for_llm_class_state(TEST_FLAG)
    def single_classify(self,state: classifyStateLogitems) -> classifyState:
        """
        å•ç”¨é€”appåˆ†ç±»ï¼ˆåˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š MAX_LOG_ITEMS æ¡ï¼‰
        """
        # system message
        goal = format_goals_for_prompt(self.goal)
        category_tree = format_category_tree_for_prompt(self.category_tree)
        #print(goal)
        #print(category_tree)
        system_message = SystemMessage(content=f"""
            # ä½ æ˜¯ä¸€ä¸ªè½¯ä»¶åˆ†ç±»ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®è½¯ä»¶åç§°,æè¿°,å°†è½¯ä»¶è¿›è¡Œåˆ†ç±»,åˆ†ç±»æœ‰categoryå’Œsub_categoryä¸¤çº§åˆ†ç±»ã€‚
            # åˆ†ç±»ç±»åˆ«
            {category_tree}
            # ç”¨æˆ·ç›®æ ‡
            {goal}
            # åˆ†ç±»è§„åˆ™
            1. å¯¹äºappä¸goalé«˜åº¦ç›¸å…³çš„æ¡ç›®,ä½¿ç”¨goalçš„åˆ†ç±»ç±»åˆ«,å¹¶å…³è”goal,link_to_goal = goal;å¦åˆ™link_to_goal = null
            2. å¯¹äºå•ç”¨é€”,ä¾æ®app_descriptionè¿›è¡Œåˆ†ç±»,è‹¥æ— æ³•åˆ†ç±»,åˆ™åˆ†ç±»ä¸ºnull
            3. è‹¥categoryæœ‰åˆ†ç±»è€Œsub_categoryæ— æ³•åˆ†ç±»,åˆ™sub_category = null
            # è¾“å‡ºæ ¼å¼ä¸ºjson,keyä¸ºå¯¹äºæ•°æ®çš„id,valueä¸ºä¸€ä¸ªlist[category,sub_category,link_to_goal]
            {{
                id:[category,sub_category,link_to_goal]
            }}
            æ³¨æ„ï¼š
            - valueå¿…é¡»æ˜¯åˆ—è¡¨ï¼ŒåŒ…å«ä¸‰ä¸ªå…ƒç´  [category, sub_category, link_to_goal]
            - æ— å€¼æ—¶ä½¿ç”¨ null
            - keyå¿…é¡»æ˜¯idï¼Œä¸æ˜¯appåç§°
            - category å’Œ sub_category å¿…é¡»åœ¨ä¸Šè¿°åˆ†ç±»ç±»åˆ«ä¸­é€‰æ‹©

            """)
        # è·å–å•ç”¨é€”çš„log_itemï¼ˆå·²ç»åœ¨è·¯ç”±æ—¶åˆ†å¥½äº†ï¼‰
        single_purpose_items = state.log_items_for_single or []
        
        if not single_purpose_items:
            logger.info("æ²¡æœ‰å•ç”¨é€”åº”ç”¨éœ€è¦åˆ†ç±»")
            return {}
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(single_purpose_items), MAX_LOG_ITEMS):
            batch = single_purpose_items[i:i + MAX_LOG_ITEMS]
            batch_num = i // MAX_LOG_ITEMS + 1
            logger.info(f"single_classify å¤„ç†ç¬¬ {batch_num} æ‰¹ï¼Œå…± {len(batch)} æ¡è®°å½•")
            
            # ä½¿ç”¨å·¥å…·å‡½æ•°æ ¼å¼åŒ– log_items
            app_content = format_log_items_table(
                batch,
                fields=["id", "app", "title"],
                app_registry=state.private_app_registry,
                group_by_app=True,
                show_app_description=True
            )
            #print(app_content)
            
            # æ„å»º human_message
            human_message = HumanMessage(content=app_content)
            messages = [system_message, human_message]
            
            # å‘é€è¯·æ±‚å¹¶è§£æç»“æœ
            result = self.chat_model.invoke(messages)
            self.recode_tokens_usage("single_classify",parse_token_usage(result))
            # è®°å½• token ä½¿ç”¨åˆ°å…¨å±€åˆ—è¡¨
            # record_token_usage("single_classify", result)
            
            # æ‰“å°åŸå§‹å“åº”å†…å®¹ä»¥ä¾¿è°ƒè¯•
            #print(f"\n=== LLM åŸå§‹å“åº” (æ‰¹æ¬¡ {batch_num}) ===")
            #print(result.content)
            #print("=== å“åº”ç»“æŸ ===\n")
            
            # è§£æ JSON ç»“æœï¼ˆå…ˆæ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°ï¼‰
            clean_content = extract_json_from_response(result.content)
            classification_result = json.loads(clean_content)
            logger.info(f"single_classify æ‰¹æ¬¡ {batch_num} æˆåŠŸè·å–åˆ†ç±»ç»“æœ")
            
            # ä½¿ç”¨é€šç”¨è§£æå‡½æ•°æ›´æ–° log_items
            single_purpose_items = parse_classification_result(single_purpose_items, classification_result, "single_classify")

        
        return {
            "result_items" : single_purpose_items
        }
 
    # node supperstep2 å¤šç”¨é€”åˆ†ç±»(ç©ºèŠ‚ç‚¹) ->classifyStateLogitems
    # @test_for_llm_class_state(TEST_FLAG)
    def multi_classify(self,state:classifyStateLogitems)->classifyStateLogitems:
        # ç©ºèŠ‚ç‚¹ï¼Œåç»­æ¥ä¸Šå¤šåˆ†ç±»è·¯ç”±
        # ç§æœ‰å˜é‡ä¼ é€’ä¸èƒ½ä¸­æ–­ä¼ é€’ï¼Œè€ŒåŒè¶…æ­¥çš„single_classè¿”å›ä¸»çŠ¶æ€ï¼Œè¿™é‡Œæ›´æ–°ä¸ä¼šå½±å“åˆ°å•åº”ç”¨åˆ†æ”¯
        return state 
    # router_by_duration_for_multi
    # @test_for_llm_class_state(TEST_FLAG)
    def router_by_duration_for_multi(self, state: classifyStateLogitems):
        """
        å¤šç”¨é€”åº”ç”¨æŒ‰æ—¶é•¿è·¯ç”±ï¼ŒçŸ­æ—¶é•¿å’Œé•¿æ—¶é•¿åˆ†å¼€å¤„ç†
        """
        log_dict = split_by_duration(state)
        log_items_for_multi_short = log_dict.get("log_items_for_multi_short", None)
        log_items_for_multi_long = log_dict.get("log_items_for_multi_long", None)
        # æ›´æ–°ä¸­é—´ç§æœ‰çŠ¶æ€
        log_items_state = classifyStateLogitems(
            private_app_registry=state.private_app_registry,
            log_items_for_single=state.log_items_for_single,
            log_items_for_multi=state.log_items_for_multi,
            log_items_for_multi_short=log_items_for_multi_short,
            log_items_for_multi_long=log_items_for_multi_long,
        )
        send_list = []
        if log_items_for_multi_short is None:
            logger.info("log_items_for_multi_short is None, æ— çŸ­æ—¶é•¿æ•°æ®")
        else:
            send_list.append(Send("multi_classify_short", log_items_state))
        if log_items_for_multi_long is None:
            logger.info("log_items_for_multi_long is None, æ— é•¿æ—¶é•¿æ•°æ®")
        else:
            send_list.append(Send("get_titles", log_items_state))
        
        return send_list
    # node supperstep 3 :å¤šç”¨é€”çŸ­æ—¶é•¿åˆ†ç±»->{result_items}
    # @test_for_llm_class_state(TEST_FLAG)
    def multi_classify_short(self,state:classifyStateLogitems) -> classifyState:
        """
        çŸ­æ—¶é•¿å¤šç”¨é€”åˆ†ç±»ï¼ˆåˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š MAX_LOG_ITEMS æ¡ï¼‰
        """
        category_tree = format_category_tree_for_prompt(self.category_tree) # ä½¿ç”¨ç±»å˜é‡
        goal = format_goals_for_prompt(self.goal)
        
        # system message
        system_message = SystemMessage(content = f"""
        ä½ æ˜¯ä¸€ä¸ªç”¨æˆ·è¡Œä¸ºåˆ†æä¸“å®¶,ä½ éœ€è¦ä¾æ®ç”¨æˆ·çš„æµè§ˆçš„ç½‘é¡µtitleå¯¹ç”¨æˆ·çš„è¡Œä¸ºè¿›è¡Œåˆ†ç±»
        # ç±»åˆ«:
        {category_tree}
        # ç”¨æˆ·ç›®æ ‡:
        {goal}
        # åˆ†ç±»è§„åˆ™:
        1. å¯¹äºtitleä¸goalé«˜åº¦ç›¸å…³çš„æ¡ç›®,ä½¿ç”¨goalçš„åˆ†ç±»ç±»åˆ«,å¹¶å…³è”goal,link_to_goal = goal;å¦åˆ™link_to_goal = null
        2. æå–å‡ºtitleä¸­çš„ç½‘ç«™åç§°å’Œç½‘ç«™æ ‡é¢˜,é€šè¿‡è¿™ä¸¤ä¸ªè¦ç´ è¿›è¡Œåˆ†ç±»
        3. ç±»åˆ«æœ‰ä¸¤ä¸ªå±‚çº§category->sub_category,åˆ†ç±»ç»“æœsub_categoryè¦å±äºcategoryã€‚å½“æ²¡æœ‰åŒ¹é…é¡¹æ—¶,åˆ†ç±»ä¸ºnull
        # è¾“å‡ºæ ¼å¼ä¸ºjson,keyä¸ºå¯¹äºæ•°æ®çš„id,valueä¸ºä¸€ä¸ªlist[category,sub_category,link_to_goal]
        {{
            id:[category,sub_category,link_to_goal]
        }}
        æ³¨æ„:
        - valueå¿…é¡»æ˜¯åˆ—è¡¨ï¼ŒåŒ…å«ä¸‰ä¸ªå…ƒç´  [category, sub_category, link_to_goal]
        - æ— å€¼æ—¶ä½¿ç”¨ null
        - category å’Œ sub_category å¿…é¡»åœ¨ä¸Šè¿°åˆ†ç±»ç±»åˆ«ä¸­é€‰æ‹©
        """)
        
        if not state.log_items_for_multi_short:
            logger.info("æ²¡æœ‰çŸ­æ—¶é•¿å¤šç”¨é€”åº”ç”¨éœ€è¦åˆ†ç±»")
            return {}
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(state.log_items_for_multi_short), MAX_LOG_ITEMS):
            batch = state.log_items_for_multi_short[i:i + MAX_LOG_ITEMS]
            batch_num = i // MAX_LOG_ITEMS + 1
            logger.info(f"multi_classify_short å¤„ç†ç¬¬ {batch_num} æ‰¹ï¼Œå…± {len(batch)} æ¡è®°å½•")
            
            items = format_log_items_table(
                batch,
                fields=["id", "app", "title", "title_analysis"]
            )
            human_message = HumanMessage(content=f"""å¯¹ä¸‹é¢çš„æ•°æ®è¿›è¡Œåˆ†ç±»:\n{items}
            """)
            messages = [system_message, human_message]
            
            # å‘é€è¯·æ±‚å¹¶è§£æç»“æœ
            result = self.chat_model.invoke(messages)
            self.recode_tokens_usage("multi_classify_short",parse_token_usage(result))
            # è®°å½• token ä½¿ç”¨åˆ°å…¨å±€åˆ—è¡¨
            # record_token_usage("multi_classify_short", result)
            
            # æ‰“å°åŸå§‹å“åº”å†…å®¹ä»¥ä¾¿è°ƒè¯•
            #print(f"\n=== LLM åŸå§‹å“åº” (æ‰¹æ¬¡ {batch_num}) ===")
            #print(result.content)
            #print("=== å“åº”ç»“æŸ ===\n")
            
            # è§£æ JSON ç»“æœï¼ˆå…ˆæ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°ï¼‰
            clean_content = extract_json_from_response(result.content)
            classification_result = json.loads(clean_content)
            logger.info(f"multi_classify_short æ‰¹æ¬¡ {batch_num} æˆåŠŸè·å–åˆ†ç±»ç»“æœ")
            
            # ä½¿ç”¨é€šç”¨è§£æå‡½æ•°æ›´æ–° log_items
            log_items_for_multi_short = parse_classification_result(state.log_items_for_multi_short, classification_result, "multi_classify_short")
            
        
        return {
            "result_items" : log_items_for_multi_short
        }

    # node supperstep 3 :è·å–title_analysis->{title_analysis_results}
    # @test_for_llm_class_state(TEST_FLAG)
    def get_titles(self,state:classifyStateLogitems)->classifyStateLogitems:
        system_message = SystemMessage(content="""
        ä½ æ˜¯ä¸€ä¸ªé€šè¿‡ç½‘ç»œæœç´¢åˆ†æçš„åŠ©æ‰‹,ä¾æ®ç½‘ç»œæœç´¢ç»“æœå’Œtitleåˆ†æç”¨æˆ·çš„æ´»åŠ¨ï¼Œè¦æ±‚ç»“æœåœ¨30å­—ä»¥å†…
        # è¾“å‡ºæ ¼å¼:str å†…å®¹ä¸º:ç”¨æˆ·æ´»åŠ¨
        """)
        for item in state.log_items_for_multi_long:
            if item.title:  # åªæ·»åŠ æœ‰titleçš„é¡¹
                human_message = HumanMessage(content=f"""æœç´¢å¹¶åˆ†æ{item.title}""")
                message = [system_message, human_message]
                result = self.chat_model.invoke(message)
                self.recode_tokens_usage("get_titles",parse_token_usage(result))
                item.title_analysis = result.content
        return {
            "log_items_for_multi_long" : state.log_items_for_multi_long
        }

    # node supperstep 4 : å¤šåˆ†ç±»é•¿æ—¶é—´ {result_items}
    # @test_for_llm_class_state(TEST_FLAG)
    def multi_classify_long(self,state:classifyStateLogitems)->classifyState:
        """
        é•¿æ—¶é•¿å¤šç”¨é€”åˆ†ç±»ï¼ˆåˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š MAX_LOG_ITEMS æ¡ï¼‰
        """
        goal = format_goals_for_prompt(self.goal)
        category_tree = format_category_tree_for_prompt(self.category_tree)
        
        system_message = SystemMessage(content=f"""
        ä½ æ˜¯ä¸€ä¸ªç”¨æˆ·è¡Œä¸ºåˆ†ç±»ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç½‘é¡µæ ‡é¢˜(Title)å’Œæ ‡é¢˜åˆ†æ(Title Analysis)å¯¹ç”¨æˆ·çš„è¡Œä¸ºè¿›è¡Œåˆ†ç±»ã€‚
        
        # åˆ†ç±»ç±»åˆ«
        {category_tree}
        
        # ç”¨æˆ·ç›®æ ‡
        {goal}
        
        # åˆ†ç±»è§„åˆ™
        1. å¯¹äºä¸goalé«˜åº¦ç›¸å…³çš„æ¡ç›®,ä½¿ç”¨goalçš„åˆ†ç±»ç±»åˆ«,å¹¶å…³è”goal,link_to_goal = goal;å¦åˆ™link_to_goal = null
        2. ä¸»è¦ä¾æ®Title Analysisæ¥ç†è§£ç”¨æˆ·çš„æ´»åŠ¨å†…å®¹,ç»“åˆTitleè¿›è¡Œåˆ†ç±»
        3. ç±»åˆ«æœ‰ä¸¤ä¸ªå±‚çº§category->sub_category,åˆ†ç±»ç»“æœsub_categoryè¦å±äºcategory
        4. è‹¥categoryæœ‰åˆ†ç±»è€Œsub_categoryæ— æ³•åˆ†ç±»,åˆ™sub_category = null
        5. è‹¥æ— æ³•åˆ†ç±»,åˆ™åˆ†ç±»ä¸ºnull
        
        # è¾“å‡ºæ ¼å¼ä¸ºjson,keyä¸ºæ•°æ®çš„id,valueä¸ºä¸€ä¸ªlist[category,sub_category,link_to_goal]
        {{
            "id":[category,sub_category,link_to_goal]
        }}

        æ³¨æ„ï¼š
        - valueå¿…é¡»æ˜¯åˆ—è¡¨ï¼ŒåŒ…å«ä¸‰ä¸ªå…ƒç´  [category, sub_category, link_to_goal]
        - æ— å€¼æ—¶ä½¿ç”¨ null
        - keyå¿…é¡»æ˜¯idï¼Œä¸æ˜¯appåç§°
        - category å’Œ sub_category å¿…é¡»åœ¨ä¸Šè¿°åˆ†ç±»ç±»åˆ«ä¸­é€‰æ‹©
        """)
        
        if not state.log_items_for_multi_long:
            logger.info("æ²¡æœ‰é•¿æ—¶é•¿å¤šç”¨é€”åº”ç”¨éœ€è¦åˆ†ç±»")
            return {}
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(state.log_items_for_multi_long), MAX_LOG_ITEMS):
            batch = state.log_items_for_multi_long[i:i + MAX_LOG_ITEMS]
            batch_num = i // MAX_LOG_ITEMS + 1
            logger.info(f"multi_classify_long å¤„ç†ç¬¬ {batch_num} æ‰¹ï¼Œå…± {len(batch)} æ¡è®°å½•")
            
            # ä½¿ç”¨å·¥å…·å‡½æ•°æ ¼å¼åŒ– log_items
            items = format_log_items_table(
                batch,
                fields=["id", "app", "title", "title_analysis"]
            )
            
            human_message = HumanMessage(content=f"""
            è¯·å¯¹ä»¥ä¸‹ç”¨æˆ·è¡Œä¸ºæ•°æ®è¿›è¡Œåˆ†ç±»ï¼š
            {items}
            """)
            
            messages = [system_message, human_message]
            
            # å‘é€è¯·æ±‚å¹¶è§£æç»“æœ
            result = self.chat_model.invoke(messages)
            self.recode_tokens_usage("multi_classify_long",parse_token_usage(result))
            # è®°å½• token ä½¿ç”¨åˆ°å…¨å±€åˆ—è¡¨
            # record_token_usage("multi_classify_long", result)
            
            # æ‰“å°åŸå§‹å“åº”å†…å®¹ä»¥ä¾¿è°ƒè¯•
            #print(f"\n=== LLM åŸå§‹å“åº” (æ‰¹æ¬¡ {batch_num}) ===")
            #print(result.content)
            #print("=== å“åº”ç»“æŸ ===\n")
            
            # è§£æ JSON ç»“æœï¼ˆå…ˆæ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°ï¼‰
            clean_content = extract_json_from_response(result.content)
            classification_result = json.loads(clean_content)
            logger.info(f"multi_classify_long æ‰¹æ¬¡ {batch_num} æˆåŠŸè·å–åˆ†ç±»ç»“æœ")
            
            # ä½¿ç”¨é€šç”¨è§£æå‡½æ•°æ›´æ–° log_items
            log_items_for_multi_long = parse_classification_result(state.log_items_for_multi_long, classification_result, "multi_classify_long")

        
        return {
            "result_items" : log_items_for_multi_long
        }

if __name__ == "__main__":
    from lifewatch.llm.llm_classify.classify.data_loader import get_real_data,filter_by_duration,deduplicate_log_items
    
    def get_state(hours = 36) -> tuple:
        state, goals, category_tree = get_real_data(hours=hours)
        state = filter_by_duration(state, min_duration=60)
        state = deduplicate_log_items(state)
        #print(f"\nå»é‡åçš„æ—¥å¿—ï¼ˆå‰10æ¡ï¼‰:")
        for item in state.log_items[:10]:
            multipurpose = "å¤šç”¨é€”" if state.app_registry[item.app].is_multipurpose else "å•ç”¨é€”"
            #print(f"  {item.app} ({multipurpose}) | {item.title} | {item.duration}s")
        
        # æµ‹è¯•è¿‡æ»¤åŠŸèƒ½
        #print(f"\næµ‹è¯•è¿‡æ»¤åŠŸèƒ½ï¼ˆåªä¿ç•™ duration >= 60 ç§’çš„è®°å½•ï¼‰:")
        #print(f"  - è¿‡æ»¤å log_items: {len(state.log_items)} æ¡")
        #print(f"  - è¿‡æ»¤å app_registry: {len(state.app_registry)} ä¸ªåº”ç”¨")
        return state, goals, category_tree
    
    main_state, goals, category_tree = get_state(hours=18)
    llm_classify = ClassifyGraph(goal=goals, category_tree=category_tree)
    config = {"configurable": {"thread_id": "thread-1"}}
    output = llm_classify.app.invoke(main_state, config)
    print(output)
    if "result_items" in output:
        result_items = output["result_items"]
        print("\n" + "="*80)
        print("ğŸ“ åˆ†ç±»ç»“æœ")
        print("="*80)
        print(f"  å…± {len(result_items)} æ¡è®°å½•")
        print("-"*80)
        for item in result_items:
            goal_str = f"ğŸ¯ {item.link_to_goal}" if item.link_to_goal else ""
            category_str = f"{item.category or 'æœªåˆ†ç±»'}/{item.sub_category or '-'}"
            print(f"  [{item.id}] {item.app:<15} | {category_str:<20} | {item.duration:>5}s | {goal_str}")
            if item.title:
                print(f"        â””â”€ æ ‡é¢˜: {item.title[:55]}{'...' if len(item.title) > 55 else ''}")
            if item.title_analysis:
                print(f"        â””â”€ åˆ†æ: {item.title_analysis[:55]}{'...' if len(item.title_analysis) > 55 else ''}")
        print("="*80)
    
    # è®¡ç®—å¹¶æ ¼å¼åŒ–è¾“å‡º tokens
    tokens_usage = llm_classify.get_total_tokens_usage()
    print("\n" + "="*50)
    print("ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡")
    print("="*50)
    print(f"  è¾“å…¥ tokens:  {tokens_usage['input_tokens']:,}")
    print(f"  è¾“å‡º tokens:  {tokens_usage['output_tokens']:,}")
    print(f"  æ€» tokens:    {tokens_usage['total_tokens']:,}")
    print(f"  æœç´¢æ¬¡æ•°:     {tokens_usage['search_count']}")
    print("="*50)
