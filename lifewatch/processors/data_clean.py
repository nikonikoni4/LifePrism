"""
åŠŸèƒ½ä»‹ç»: æ¥å—awçš„æ•°æ®,ä¾æ®å•å’Œå¤šç”¨é€”æå–éœ€è¦è¯†åˆ«çš„item(é‡å¤å†…å®¹è·³è¿‡)

åŒ…å«ä¸¤ä¸ªç‰ˆæœ¬:
- clean_activitywatch_data: åŸå§‹ç‰ˆæœ¬ï¼ˆä¿ç•™å…¼å®¹ï¼‰
- clean_activitywatch_data_v2: é‡æ„ç‰ˆæœ¬ï¼ˆç»„ä»¶åŒ–æ¶æ„ï¼‰
"""
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple
import pytz
from lifewatch.storage import LWBaseDataProvider
from lifewatch.processors import processor_aw_data_provider
from lifewatch.utils import is_multipurpose_app
from lifewatch.config import LOCAL_TIMEZONE
from lifewatch.config.settings_manager import settings
from lifewatch.config.database import get_table_columns
from lifewatch.llm.llm_classify import AppInFo, LogItem, classifyState
from lifewatch.utils import get_logger, DEBUG

# å¯¼å…¥é‡æ„ç»„ä»¶
from lifewatch.processors.components import (
    CategoryCache,
    EventTransformer,
    CacheMatcher,
    ClassifyCollector,
)
from lifewatch.processors.models import ProcessedEvent

logger = get_logger(__name__, DEBUG)


def create_dict_from_table_columns(table_name: str, values: dict = None) -> dict:
    """
    æ ¹æ®æ•°æ®åº“è¡¨é…ç½®åŠ¨æ€åˆ›å»ºå­—å…¸
    
    Args:
        table_name: è¡¨åï¼Œç”¨äºè·å–åˆ—é…ç½®
        values: å¯é€‰çš„å­—æ®µå€¼å­—å…¸ï¼Œæœªæä¾›çš„å­—æ®µé»˜è®¤ä¸ºNone
    
    Returns:
        dict: åŒ…å«æ‰€æœ‰è¡¨åˆ—çš„å­—å…¸ï¼Œæœªæä¾›çš„å€¼ä¸ºNone
    """
    columns = get_table_columns(table_name)
    result = {col: None for col in columns}
    if values:
        for key, value in values.items():
            if key in result:
                result[key] = value
    return result


def convert_utc_to_local(utc_timestamp_str: str, target_tz: str ) -> str:
    """
    å°†ActivityWatch APIè¿”å›çš„UTCæ—¶é—´æˆ³è½¬æ¢ä¸ºç”¨æˆ·æœ¬åœ°æ—¶é—´
    
    Args:
        utc_timestamp_str: APIè¿”å›çš„UTCæ—¶é—´æˆ³ï¼Œæ ¼å¼å¦‚ "2025-11-19T08:14:52.000000+00:00"
        target_tz: ç›®æ ‡æ—¶åŒºï¼Œé»˜è®¤ä¸ºç”¨æˆ·è®¾ç½®æ—¶åŒº
    
    Rlifewatch.utils.py.utilss:
        str: æ ¼å¼åŒ–åçš„æœ¬åœ°æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼å¦‚ "2025-11-19 16:14:52"
    
    Note:
        - è¾“å…¥ï¼šISO 8601æ ¼å¼çš„UTCæ—¶é—´æˆ³
        - è¾“å‡ºï¼šç”¨æˆ·æœ¬åœ°æ—¶åŒºçš„æ ¼å¼åŒ–æ—¶é—´å­—ç¬¦ä¸²
        - ä¿æŒæ¯«ç§’çº§æ—¶é—´ç²¾åº¦
    """
    try:
        # 1. è§£æISO 8601æ ¼å¼çš„UTCæ—¶é—´æˆ³
        # å¤„ç†Zåç¼€ï¼ˆè¡¨ç¤ºUTCï¼‰å¹¶æ›¿æ¢ä¸º+00:00
        clean_timestamp = utc_timestamp_str.replace('Z', '+00:00')
        dt_utc = datetime.fromisoformat(clean_timestamp)
        
        # 2. è½¬æ¢ä¸ºç”¨æˆ·æŒ‡å®šçš„æ—¶åŒº
        target_timezone = pytz.timezone(target_tz)
        dt_local = dt_utc.astimezone(target_timezone)
        
        # 3. æ ¼å¼åŒ–è¾“å‡ºï¼Œä¿æŒæ¯«ç§’ç²¾åº¦
        return dt_local.strftime('%Y-%m-%d %H:%M:%S')
        
    except Exception as e:
        # é”™è¯¯å¤„ç†ï¼šå¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²å¹¶è®°å½•è­¦å‘Š
        # print(f"âš ï¸  æ—¶é—´æˆ³è½¬æ¢å¤±è´¥: {utc_timestamp_str} -> {str(e)}")
        logger.warning(f"æ—¶é—´æˆ³è½¬æ¢å¤±è´¥: {utc_timestamp_str} -> {str(e)}")
        return utc_timestamp_str




def clean_activitywatch_data_old(
    start_time: datetime, 
    end_time: datetime, 
    category_map_cache_df: pd.DataFrame
) -> Tuple[pd.DataFrame, classifyState]:
    """
    å®Œæ•´çš„æ•°æ®æ¸…æ´—æµç¨‹ï¼šä» AW è·å–æ•°æ® + æ—¶é—´æˆ³æ ‡å‡†åŒ– + çŸ­æ´»åŠ¨è¿‡æ»¤ + æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–
    
    Args:
        start_time: å¼€å§‹æ—¶é—´ (datetime å¯¹è±¡)
        end_time: ç»“æŸæ—¶é—´ (datetime å¯¹è±¡)
        category_map_cache_df: åº”ç”¨ç›®çš„åˆ†ç±»DataFrameï¼ŒåŒ…å«category_map_cache_dfè¡¨ä¸­çš„æ•°æ®
    
    Returns:
        Tuple[pd.DataFrame, classifyState]:
            - filtered_events_df: æ¸…æ´—åçš„äº‹ä»¶æ•°æ®DataFrame
            - classify_state: åŒ…å«å¾…åˆ†ç±»åº”ç”¨ä¿¡æ¯çš„classifyStateå¯¹è±¡
                - app_registry: åº”ç”¨æ³¨å†Œè¡¨ {app: AppInFo}
                - log_items: å¾…åˆ†ç±»çš„æ—¥å¿—é¡¹åˆ—è¡¨
                - result_items: åˆå§‹ä¸ºNone
    
    Process:
        1. ä» ActivityWatch æ•°æ®åº“è·å–åŸå§‹äº‹ä»¶
        2. æ—¶é—´æˆ³æ ‡å‡†åŒ–ï¼šUTC -> æœ¬åœ°æ—¶é—´
        3. çŸ­æ´»åŠ¨è¿‡æ»¤ï¼šåˆ é™¤ < 60ç§’çš„äº‹ä»¶
        4. æ•°æ®åº“æŸ¥è¯¢ï¼šå¦‚æœåº”ç”¨å·²å­˜åœ¨åˆ†ç±»æ•°æ®ï¼Œç›´æ¥è·å–
        5. æ„å»ºclassifyStateï¼šæ”¶é›†å¾…åˆ†ç±»åº”ç”¨çš„ä¿¡æ¯
    """
    # ä» ActivityWatch è·å–åŸå§‹æ•°æ®
    raw_events = processor_aw_data_provider.get_window_events(
        start_time=start_time,
        end_time=end_time
    )
    
    logger.info(f"ğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—æµç¨‹...")
    logger.info(f"ğŸ“¥ åŸå§‹æ•°æ®: {len(raw_events)} ä¸ªäº‹ä»¶")
    
    lower_bound = settings.data_cleaning_threshold
    removed_count = 0  # åˆå§‹åŒ–è¢«è¿‡æ»¤äº‹ä»¶è®¡æ•°
    filtered_events_list = []  # è¿‡æ»¤åçš„äº‹ä»¶åˆ—è¡¨
    
    # å·²æ·»åŠ çš„å¾…åˆ†ç±»åº”ç”¨
    apps_to_classify_set = set()  # å·²æ·»åŠ çš„å¾…åˆ†ç±»åº”ç”¨é›†åˆ ç”¨äºåˆ¤æ–­æ˜¯å¦å·²ç»æ·»åŠ 
    title_to_classify_set = set()  # å·²æ·»åŠ çš„å¾…åˆ†ç±»titleé›†åˆ ç”¨äºåˆ¤æ–­æ˜¯å¦å·²ç»æ·»åŠ 
    
    # classifyState ç»„ä»¶
    app_registry: Dict[str, AppInFo] = {}  # åº”ç”¨æ³¨å†Œè¡¨
    log_items: List[LogItem] = []  # å¾…åˆ†ç±»æ—¥å¿—é¡¹
    log_item_id_counter = 0  # LogItem ID è®¡æ•°å™¨
    
    # å·²ç»åˆ†ç±»çš„åº”ç”¨ï¼ˆå•ä¸€ç”¨é€”appå’Œå¤šç”¨é€”titleï¼‰
    # ä»¥åŠå·²å­˜åœ¨çš„app_descriptionï¼Œé¿å…LLMé‡å¤æœç´¢
    logger.debug(f"åŸå§‹ category_map_cache_df é•¿åº¦: {len(category_map_cache_df) if category_map_cache_df is not None else 0}")
    if category_map_cache_df is not None and not category_map_cache_df.empty:
        # ç›´æ¥ä½¿ç”¨ state å­—æ®µè¿‡æ»¤ï¼ˆstate=0 è¡¨ç¤ºå¯¹åº”çš„åˆ†ç±»è¢«ç¦ç”¨ï¼‰
        valid_df = category_map_cache_df[
            category_map_cache_df.get('state', 1) == 1
        ].copy() if 'state' in category_map_cache_df.columns else category_map_cache_df.copy()
        logger.debug(f"è¿‡æ»¤åçš„ valid_df é•¿åº¦: {len(valid_df)}")
        # è·å–å·²å­˜åœ¨çš„å•ä¸€ç”¨é€”çš„åº”ç”¨é›†åˆï¼ˆåªåŒ…å« is_multipurpose_app == 0 çš„ï¼‰
        single_purpose_df = valid_df[valid_df['is_multipurpose_app'] == 0]
        categorized_single_purpose_apps = set(single_purpose_df['app'].unique())
        # è·å–å·²å­˜åœ¨çš„å¤šç”¨é€”åº”ç”¨é›†åˆï¼ˆåªåŒ…å« is_multipurpose_app == 1 çš„ï¼‰
        multi_purpose_df = valid_df[valid_df['is_multipurpose_app'] == 1]
        categorized_multipurpose_apps = set(multi_purpose_df['app'].unique())
        # è·å–éå•ä¸€ç”¨é€”çš„titleé›†åˆ
        categorized_mutilpurpose_titles = set(multi_purpose_df['title'].unique())
        
        # åˆ›å»º app -> (category_id, sub_category_id, link_to_goal_id) æ˜ å°„
        app_category_map: Dict[str, tuple] = {}
        title_category_map: Dict[str, tuple] = {}
        
        for _, row in valid_df.iterrows():
            app = row.get('app', '').lower()
            title_val = row.get('title', '').lower() if row.get('title') else ''
            cat_id = row.get('category_id')
            sub_cat_id = row.get('sub_category_id')
            goal_id = row.get('link_to_goal_id')  # è·å– link_to_goal_id
            is_multi = row.get('is_multipurpose_app', 0)
            if app == "antigravity":
                logger.debug("="*20)
                logger.debug(f"app: {app}, goal_id: {goal_id}")
                logger.debug("="*20)
            
            if app and cat_id:
                if is_multi == 0 and app not in app_category_map:
                    app_category_map[app] = (cat_id, sub_cat_id, goal_id)
                elif is_multi == 1 and title_val:
                    title_category_map[title_val] = (cat_id, sub_cat_id, goal_id)
        
        # åˆ›å»º app -> app_description æ˜ å°„ï¼Œç”¨äºå¤ç”¨å·²æœ‰çš„åº”ç”¨æè¿°
        # æ³¨æ„ï¼šç»Ÿä¸€è½¬ä¸ºå°å†™ï¼Œä»¥åŒ¹é…åç»­äº‹ä»¶å¤„ç†ä¸­çš„ app_name.lower()
        app_description_map: Dict[str, str] = {}
        for _, row in category_map_cache_df.iterrows():
            app = row.get('app', '').lower()  # ç»Ÿä¸€è½¬ä¸ºå°å†™
            desc = row.get('app_description', '')
            if app and desc and app not in app_description_map:
                app_description_map[app] = desc
    else:
        categorized_single_purpose_apps = set()
        categorized_multipurpose_apps = set()  # æ–°å¢
        categorized_mutilpurpose_titles = set()
        app_category_map = {}
        title_category_map = {}
        app_description_map = {}
    
    # output - ä½¿ç”¨åŠ¨æ€å­—å…¸æ ¼å¼é…ç½®
    filtered_events_df = pd.DataFrame(columns=get_table_columns('user_app_behavior_log'))
    print(get_table_columns('user_app_behavior_log'))
    for event in raw_events:
        duration = int(event.get('duration', 0))
        if duration >= lower_bound:
            # è½¬æ¢æ—¶é—´æˆ³
            local_start_time = convert_utc_to_local(event.get('timestamp', ''), LOCAL_TIMEZONE)
            # è®¡ç®—ç»“æŸæ—¶é—´
            start_dt = datetime.strptime(local_start_time, '%Y-%m-%d %H:%M:%S')
            end_dt = start_dt + timedelta(seconds=duration)
            local_end_time = end_dt.strftime('%Y-%m-%d %H:%M:%S')
            # è·å¾—åº”ç”¨åç§°
            app_name = event.get('data', {}).get('app', None)
            
            if app_name:
                app_name = app_name.lower().strip().split('.exe')[0]
                # è·å¾—title
                title = event.get('data', {}).get('title', None)
                if title:
                    title = title.split('å’Œå¦å¤–')[0].strip().lower()
                
                is_multipurpose = is_multipurpose_app(app_name)
                
                # ä½¿ç”¨åŠ¨æ€å­—å…¸åˆ›å»ºäº‹ä»¶æ•°æ®
                filtered_event = create_dict_from_table_columns('user_app_behavior_log', {
                    'id': event.get('id', ''),
                    'start_time': local_start_time,
                    'end_time': local_end_time,
                    'duration': duration,
                    'app': app_name,
                    'title': title,
                    'is_multipurpose_app': 1 if is_multipurpose else 0
                })
                
                # 1.appå·²ç»è¢«åˆ†ç±» ä¸” appæ˜¯å•ä¸€ç”¨é€”çš„ ï¼š ç›´æ¥è¿›è¡Œåˆ†ç±» 
                if app_name in categorized_single_purpose_apps and not is_multipurpose:
                    # å¯¹äºå•ä¸€åº”ç”¨ï¼Œç›´æ¥ä»æ˜ å°„è·å–åˆ†ç±»ID
                    cat_ids = app_category_map.get(app_name)
                    if cat_ids:
                        filtered_event['category_id'] = cat_ids[0]
                        filtered_event['sub_category_id'] = cat_ids[1]
                        filtered_event['link_to_goal_id'] = cat_ids[2] if len(cat_ids) > 2 else None
                        logger.debug(f"âœ… æˆåŠŸè·å–åˆ†ç±»æ•°æ®: category_id={cat_ids[0]}, sub_category_id={cat_ids[1]}, link_to_goal_id={cat_ids[2] if len(cat_ids) > 2 else None}")
                
                # 2.å¤šç”¨é€”appå·²ç»è¢«åˆ†ç±» ä¸” å¯¹åº”çš„titleä¹Ÿæœ‰åˆ†ç±»è®°å½• ï¼š æ ¹æ®titleè·å–åˆ†ç±»
                elif app_name in categorized_multipurpose_apps and title and title in categorized_mutilpurpose_titles:
                    # å¯¹äºå¤šåº”ç”¨åœºæ™¯ï¼Œæ ¹æ®titleåŒ¹é…åˆ†ç±»æ•°æ®
                    cat_ids = title_category_map.get(title)
                    if cat_ids:
                        filtered_event['category_id'] = cat_ids[0]
                        filtered_event['sub_category_id'] = cat_ids[1]
                        filtered_event['link_to_goal_id'] = cat_ids[2] if len(cat_ids) > 2 else None
                        logger.debug(f"âœ… æˆåŠŸè·å–åˆ†ç±»æ•°æ®: category_id={cat_ids[0]}, sub_category_id={cat_ids[1]}, link_to_goal_id={cat_ids[2] if len(cat_ids) > 2 else None}")
                        logger.debug(f"âœ… å¤šç”¨é€”åŒ¹é…æˆåŠŸ: app_name={app_name}, title={title}")
                # 3. appæœªè¢«åˆ†ç±»ï¼Œä¸”æ˜¯å•ä¸€ç”¨é€”çš„ 
                elif not is_multipurpose:
                    # 3.1 appæœªè¢«åˆ†ç±»ï¼Œä¸”æ˜¯å•ä¸€ç”¨é€”çš„ ä¸” æœªè¢«æ·»åŠ åˆ°å¾…åˆ†ç±»åˆ—è¡¨ ï¼š åŠ å…¥å¾…åˆ†ç±»åˆ—è¡¨
                    # ä¸€ä¸ªappåªéœ€è¦åŠ å…¥ä¸€æ¬¡ï¼Œåªåˆ›å»ºä¸€ä¸ªLogItem
                    if app_name not in apps_to_classify_set:
                        # æ·»åŠ åˆ° app_registryï¼Œå¤ç”¨å·²å­˜åœ¨çš„app_description
                        existing_desc = app_description_map.get(app_name, "")
                        app_registry[app_name] = AppInFo(
                            description=existing_desc,  # å¤ç”¨å·²æœ‰æè¿°ï¼Œç©ºåˆ™å¾…LLMå¡«å……
                            is_multipurpose=False,
                            titles=[title]
                        )
                        apps_to_classify_set.add(app_name)
                        
                        # åˆ›å»º LogItem å¹¶æ·»åŠ åˆ° log_itemsï¼ˆæ¯ä¸ªå•ç”¨é€”appåªéœ€ä¸€ä¸ªï¼‰
                        log_items.append(LogItem(
                            id=log_item_id_counter,
                            app=app_name,
                            duration=int(duration),
                            title=title
                        ))
                        log_item_id_counter += 1
                
                # 4.appæœªè¢«åˆ†ç±»ï¼Œä¸”æ˜¯å¤šç”¨é€”çš„ ï¼š åŠ å…¥å¾…åˆ†ç±»åˆ—è¡¨
                elif is_multipurpose:
                    # ç¡®ä¿ app åœ¨ registry ä¸­
                    if app_name not in apps_to_classify_set:
                        # å¤ç”¨å·²å­˜åœ¨çš„app_description
                        existing_desc = app_description_map.get(app_name, "")
                        app_registry[app_name] = AppInFo(
                            description=existing_desc,  # å¤ç”¨å·²æœ‰æè¿°ï¼Œç©ºåˆ™å¾…LLMå¡«å……
                            is_multipurpose=True,
                            titles=[]
                        )
                        apps_to_classify_set.add(app_name)
                    
                    # 4.1 appæœªè¢«åˆ†ç±»ï¼Œä¸”æ˜¯å¤šç”¨é€”çš„ ä¸” æœªè¢«æ·»åŠ åˆ°å¾…åˆ†ç±»åˆ—è¡¨ ï¼š åŠ å…¥å¾…åˆ†ç±»åˆ—è¡¨
                    # ç‰¹åˆ«çš„ï¼Œä½¿ç”¨titleè¿›è¡Œåˆ†ç±»ï¼Œä¸€ä¸ªtitleæ·»åŠ ä¸€æ¬¡ï¼Œappåç§°å¯é‡å¤
                    if title and title not in title_to_classify_set:
                        # æ·»åŠ  title åˆ°å¯¹åº” app çš„ titles åˆ—è¡¨
                        if app_registry[app_name].titles is not None:
                            app_registry[app_name].titles.append(title)
                        
                        # åˆ›å»º LogItem å¹¶æ·»åŠ åˆ° log_items
                        log_items.append(LogItem(
                            id=log_item_id_counter,
                            app=app_name,
                            duration=int(duration),
                            title=title
                        ))
                        log_item_id_counter += 1
                        title_to_classify_set.add(title)
                
                # ä½¿ç”¨åˆ—è¡¨æ”¶é›†æ‰€æœ‰äº‹ä»¶ï¼Œæœ€åä¸€æ¬¡æ€§åˆ›å»ºDataFrame
                filtered_events_list.append(filtered_event)
        else:
            # è®°å½•è¢«è¿‡æ»¤çš„çŸ­æš‚æ´»åŠ¨
            removed_count += 1
    
    # ä¸€æ¬¡æ€§åˆ›å»ºDataFrameï¼Œé¿å…å¾ªç¯ä¸­çš„concatè­¦å‘Š
    if filtered_events_list:
        filtered_events_df = pd.DataFrame(filtered_events_list)
    
    # æ„å»º classifyState
    classify_state = classifyState(
        app_registry=app_registry,
        log_items=log_items,
        result_items=None
    )
    
    # ç»Ÿè®¡æ—¥å¿—
    single_count = len([item for item in log_items if not app_registry.get(item.app, AppInFo(description="", is_multipurpose=False)).is_multipurpose])
    multi_count = len([item for item in log_items if app_registry.get(item.app, AppInFo(description="", is_multipurpose=False)).is_multipurpose])
    
    logger.info(f"ğŸ“Š è¿‡æ»¤ç»Ÿè®¡: æ€»äº‹ä»¶ {len(raw_events)} -> ä¿ç•™ {len(filtered_events_df)} -> åˆ é™¤ {removed_count}")
    logger.info(f"ğŸ“Š å¾…åˆ†ç±»ç»Ÿè®¡: æ€»é¡¹ç›® {len(log_items)} -> å•ç”¨é€” {single_count} -> å¤šç”¨é€” {multi_count}")
    logger.info(f"ğŸ“Š åº”ç”¨æ³¨å†Œè¡¨: {len(app_registry)} ä¸ªåº”ç”¨")
    return filtered_events_df, classify_state


# ============================================================================
# é‡æ„ç‰ˆæœ¬ - ç»„ä»¶åŒ–æ¶æ„
# ============================================================================

def _events_to_dataframe(events: List[ProcessedEvent]) -> pd.DataFrame:
    """
    å°† ProcessedEvent åˆ—è¡¨è½¬æ¢ä¸º DataFrame
    
    Args:
        events: ProcessedEvent åˆ—è¡¨
        
    Returns:
        åŒ…å«äº‹ä»¶æ•°æ®çš„ DataFrame
    """
    if not events: 
        return pd.DataFrame(columns=get_table_columns('user_app_behavior_log'))
    print(events[0].to_dict().keys())
    return pd.DataFrame([event.to_dict() for event in events])



def clean_activitywatch_data(
    start_time: datetime, 
    end_time: datetime, 
    category_map_cache_df: pd.DataFrame
) -> Tuple[pd.DataFrame, classifyState]:
    """
    å®Œæ•´çš„æ•°æ®æ¸…æ´—æµç¨‹ï¼ˆé‡æ„ç‰ˆæœ¬ - ç»„ä»¶åŒ–æ¶æ„ï¼‰
    
    ä¸åŸç‰ˆæœ¬ clean_activitywatch_data åŠŸèƒ½ç›¸åŒï¼Œä½†ä½¿ç”¨ç»„ä»¶åŒ–è®¾è®¡ï¼š
    - CategoryCache: ç¼“å­˜ç´¢å¼•ç®¡ç†
    - EventTransformer: äº‹ä»¶è½¬æ¢ä¸æ ‡å‡†åŒ–
    - CacheMatcher: ç¼“å­˜åŒ¹é…ç­–ç•¥
    - ClassifyCollector: å¾…åˆ†ç±»é¡¹æ”¶é›†
    
    Args:
        start_time: å¼€å§‹æ—¶é—´ (datetime å¯¹è±¡)
        end_time: ç»“æŸæ—¶é—´ (datetime å¯¹è±¡)
        category_map_cache_df: åˆ†ç±»ç¼“å­˜ DataFrame
    
    Returns:
        Tuple[pd.DataFrame, classifyState]:
            - filtered_events_df: æ¸…æ´—åçš„äº‹ä»¶æ•°æ® DataFrame
            - classify_state: åŒ…å«å¾…åˆ†ç±»åº”ç”¨ä¿¡æ¯çš„ classifyState å¯¹è±¡
    """
    # 1. è·å–åŸå§‹æ•°æ®
    raw_events = processor_aw_data_provider.get_window_events(
        start_time=start_time,
        end_time=end_time
    )
    logger.info(f"ğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—æµç¨‹ (v2)...")
    logger.info(f"ğŸ“¥ åŸå§‹æ•°æ®: {len(raw_events)} ä¸ªäº‹ä»¶")
    
    # 2. åˆå§‹åŒ–ç»„ä»¶
    cache = CategoryCache(category_map_cache_df)
    transformer = EventTransformer()
    matcher = CacheMatcher(cache)
    collector = ClassifyCollector(cache)
    
    logger.debug(f"ğŸ“¦ ç¼“å­˜ç»Ÿè®¡: {cache.get_stats()}")
    
    # 3. è½¬æ¢äº‹ä»¶
    events, removed_count = transformer.transform_batch(raw_events)
    logger.debug(f"ğŸ”„ äº‹ä»¶è½¬æ¢å®Œæˆ: æœ‰æ•ˆ {len(events)}, è¿‡æ»¤ {removed_count}")
    
    # 4. åŒ¹é…ç¼“å­˜ & æ”¶é›†å¾…åˆ†ç±»é¡¹
    for event in events:
        matcher.match(event) # åŒ¹é…åçš„æ•°æ®æ ‡è®° cache_matched = True
        collector.collect(event)
    
    # 5. æ„å»ºè¾“å‡º
    filtered_events_df = _events_to_dataframe(events)
    classify_state = collector.build_state()
    
    # 6. æ—¥å¿—ç»Ÿè®¡
    match_stats = matcher.get_stats()
    collect_stats = collector.get_stats()
    
    logger.info(f"ğŸ“Š è¿‡æ»¤ç»Ÿè®¡: æ€»äº‹ä»¶ {len(raw_events)} -> ä¿ç•™ {len(events)} -> åˆ é™¤ {removed_count}")
    logger.info(f"ğŸ“Š ç¼“å­˜åŒ¹é…: å‘½ä¸­ {match_stats['matched']}, æœªå‘½ä¸­ {match_stats['missed']}")
    logger.info(f"ğŸ“Š å¾…åˆ†ç±»ç»Ÿè®¡: æ€»é¡¹ç›® {collect_stats['total']} -> å•ç”¨é€” {collect_stats['single']} -> å¤šç”¨é€” {collect_stats['multi']}")
    logger.info(f"ğŸ“Š åº”ç”¨æ³¨å†Œè¡¨: {collect_stats['apps']} ä¸ªåº”ç”¨")
    
    return filtered_events_df, classify_state




if __name__ == "__main__":
    def test_v1_and_v2():
        from datetime import timedelta
    
        # æµ‹è¯•æ—¶é—´èŒƒå›´
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=24)  # æµ‹è¯•24å°æ—¶æ•°æ®
        
        # åŠ è½½ç¼“å­˜æ•°æ®
        category_map_cache_df = LWBaseDataProvider().load_category_map_cache_V2()
        print(f"ç¼“å­˜æ•°æ®: {len(category_map_cache_df)} è¡Œ")
        
        print("\n" + "="*60)
        print("æµ‹è¯•åŸç‰ˆæœ¬ (v1)")
        print("="*60)
        filtered_events_df_v1, classify_state_v1 = clean_activitywatch_data_old(
            start_time, end_time, category_map_cache_df
        )
        print(f"è¿‡æ»¤åäº‹ä»¶æ•°: {len(filtered_events_df_v1)}")
        print(f"å¾…åˆ†ç±»åº”ç”¨: {list(classify_state_v1.app_registry.keys())}")
        print(f"å¾…åˆ†ç±»æ—¥å¿—é¡¹æ•°: {len(classify_state_v1.log_items)}")
        
        print("\n" + "="*60)
        print("æµ‹è¯•é‡æ„ç‰ˆæœ¬ (v2)")
        print("="*60)
        filtered_events_df_v2, classify_state_v2 = clean_activitywatch_data(
            start_time, end_time, category_map_cache_df
        )
        print(f"è¿‡æ»¤åäº‹ä»¶æ•°: {len(filtered_events_df_v2)}")
        print(f"å¾…åˆ†ç±»åº”ç”¨: {list(classify_state_v2.app_registry.keys())}")
        print(f"å¾…åˆ†ç±»æ—¥å¿—é¡¹æ•°: {len(classify_state_v2.log_items)}")
        
        # å¯¹æ¯”ç»“æœ
        print("\n" + "="*60)
        print("ç»“æœå¯¹æ¯”")
        print("="*60)
        print(f"äº‹ä»¶æ•°ä¸€è‡´: {len(filtered_events_df_v1) == len(filtered_events_df_v2)}")
        print(f"å¾…åˆ†ç±»æ•°ä¸€è‡´: {len(classify_state_v1.log_items) == len(classify_state_v2.log_items)}")
        print(f"åº”ç”¨æ•°ä¸€è‡´: {len(classify_state_v1.app_registry) == len(classify_state_v2.app_registry)}")
        
        # è¯¦ç»†å¯¹æ¯”åº”ç”¨
        v1_apps = set(classify_state_v1.app_registry.keys())
        v2_apps = set(classify_state_v2.app_registry.keys())
        if v1_apps != v2_apps:
            print(f"v1 ç‹¬æœ‰: {v1_apps - v2_apps}")
            print(f"v2 ç‹¬æœ‰: {v2_apps - v1_apps}")
        else:
            print("åº”ç”¨é›†åˆå®Œå…¨ä¸€è‡´ [OK]")

    def special_test():
        """
        ç‰¹æ®Šæµ‹è¯•ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•æ•°æ®æ¸…æ´—ç»„ä»¶
        
        æµ‹è¯• category_map_cache_df æ•°æ®ï¼š
        | id | app | title | description | åˆ†ç±» | å•/å¤šç”¨é€” |
        | :--- | :--- | :--- | :--- | :--- | :--- |
        | 1 | single_app0 | None | None | None | å•ç”¨é€” | (éæ³•æ•°æ®: æ— title)
        | 2 | single_app1 | None | single_app1_des | None | å•ç”¨é€” |
        | 3 | single_app2 | single_app2_title | None | None | å•ç”¨é€” |
        | 4 | single_app3 | single_app3_title | single_app3_des | None | å•ç”¨é€” |
        | 5 | single_app4 | single_app4_title | single_app4_des | (cat-work, sub-coding, goal-project) | å•ç”¨é€” |
        | 6 | multi_app0 | None | None | None | å¤šç”¨é€” | (éæ³•æ•°æ®: æ— title)
        | 7 | multi_app1 | None | multi_app1_des | None | å¤šç”¨é€” | (éæ³•æ•°æ®: æ— title)
        | 8 | multi_app2 | multi_app2_title | None | None | å¤šç”¨é€” |
        | 9 | multi_app3 | multi_app3_title | multi_app3_des | None | å¤šç”¨é€” |
        | 10 | multi_app4 | multi_app4_title | multi_app4_des | (cat-entertainment, sub-tv, None) | å¤šç”¨é€” |
        """
        import pandas as pd
        from lifewatch.processors.components import (
            CategoryCache, EventTransformer, CacheMatcher, ClassifyCollector
        )
        from lifewatch.processors.models import ProcessedEvent
        
        print("\n" + "="*70)
        print("ç‰¹æ®Šæµ‹è¯•: æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•")
        print("="*70)
        
        # ========================================
        # 1. æ„å»ºæ¨¡æ‹Ÿçš„ category_map_cache_df
        # ========================================
        cache_data = [
            # id=1: å•ç”¨é€”ï¼Œæ— titleæ— descriptionæ— åˆ†ç±» (è¾¹ç•Œ)
            {
                'id': 1, 'app': 'single_app0', 'title': None, 
                'is_multipurpose_app': 0, 'app_description': None,
                'category_id': None, 'sub_category_id': None, 'link_to_goal_id': None,
                'state': 1
            },
            # id=2: å•ç”¨é€”ï¼Œæ— titleæœ‰descriptionæ— åˆ†ç±»
            {
                'id': 2, 'app': 'single_app1', 'title': None,
                'is_multipurpose_app': 0, 'app_description': 'single_app1_des',
                'category_id': None, 'sub_category_id': None, 'link_to_goal_id': None,
                'state': 1
            },
            # id=3: å•ç”¨é€”ï¼Œæœ‰titleæ— descriptionæ— åˆ†ç±»
            {
                'id': 3, 'app': 'single_app2', 'title': 'single_app2_title',
                'is_multipurpose_app': 0, 'app_description': None,
                'category_id': None, 'sub_category_id': None, 'link_to_goal_id': None,
                'state': 1
            },
            # id=4: å•ç”¨é€”ï¼Œæœ‰titleæœ‰descriptionæ— åˆ†ç±»
            {
                'id': 4, 'app': 'single_app3', 'title': 'single_app3_title',
                'is_multipurpose_app': 0, 'app_description': 'single_app3_des',
                'category_id': None, 'sub_category_id': None, 'link_to_goal_id': None,
                'state': 1
            },
            # id=5: å•ç”¨é€”ï¼Œå®Œæ•´æ•°æ®ï¼Œæœ‰åˆ†ç±»
            {
                'id': 5, 'app': 'single_app4', 'title': 'single_app4_title',
                'is_multipurpose_app': 0, 'app_description': 'single_app4_des',
                'category_id': 'cat-work', 'sub_category_id': 'sub-coding', 'link_to_goal_id': 'goal-project',
                'state': 1
            },
            # id=6: å¤šç”¨é€”ï¼Œæ— titleæ— descriptionæ— åˆ†ç±» (è¾¹ç•Œ)
            {
                'id': 6, 'app': 'multi_app0', 'title': None,
                'is_multipurpose_app': 1, 'app_description': None,
                'category_id': None, 'sub_category_id': None, 'link_to_goal_id': None,
                'state': 1
            },
            # id=7: å¤šç”¨é€”ï¼Œæ— titleæœ‰descriptionæ— åˆ†ç±»
            {
                'id': 7, 'app': 'multi_app1', 'title': None,
                'is_multipurpose_app': 1, 'app_description': 'multi_app1_des',
                'category_id': None, 'sub_category_id': None, 'link_to_goal_id': None,
                'state': 1
            },
            # id=8: å¤šç”¨é€”ï¼Œæœ‰titleæ— descriptionæ— åˆ†ç±»
            {
                'id': 8, 'app': 'multi_app2', 'title': 'multi_app2_title',
                'is_multipurpose_app': 1, 'app_description': None,
                'category_id': None, 'sub_category_id': None, 'link_to_goal_id': None,
                'state': 1
            },
            # id=9: å¤šç”¨é€”ï¼Œæœ‰titleæœ‰descriptionæ— åˆ†ç±»
            {
                'id': 9, 'app': 'multi_app3', 'title': 'multi_app3_title',
                'is_multipurpose_app': 1, 'app_description': 'multi_app3_des',
                'category_id': None, 'sub_category_id': None, 'link_to_goal_id': None,
                'state': 1
            },
            # id=10: å¤šç”¨é€”ï¼Œå®Œæ•´æ•°æ®ï¼Œæœ‰åˆ†ç±»
            {
                'id': 10, 'app': 'multi_app4', 'title': 'multi_app4_title',
                'is_multipurpose_app': 1, 'app_description': 'multi_app4_des',
                'category_id': 'cat-entertainment', 'sub_category_id': 'sub-tv', 'link_to_goal_id': None,
                'state': 1
            },
        ]
        category_map_cache_df = pd.DataFrame(cache_data)
        
        print("\n[1] æ„å»ºçš„ category_map_cache_df:")
        print(category_map_cache_df[['id', 'app', 'title', 'is_multipurpose_app', 'category_id']].to_string())
        
        # ========================================
        # 2. æµ‹è¯• CategoryCache æ„å»º
        # ========================================
        print("\n[2] æµ‹è¯• CategoryCache æ„å»º:")
        cache = CategoryCache(category_map_cache_df)
        stats = cache.get_stats()
        print(f"  ç¼“å­˜ç»Ÿè®¡: {stats}")
        
        # éªŒè¯å•ç”¨é€”ç¼“å­˜ (åªæœ‰ id=5 æœ‰æœ‰æ•ˆåˆ†ç±»)
        print(f"\n  å•ç”¨é€” single_app4 ç¼“å­˜å‘½ä¸­: {cache.is_single_purpose_cached('single_app4')}")
        print(f"  å•ç”¨é€” single_app4 åˆ†ç±»: {cache.get_single_purpose_category('single_app4')}")
        print(f"  å•ç”¨é€” single_app0 ç¼“å­˜å‘½ä¸­: {cache.is_single_purpose_cached('single_app0')}")  # æ— åˆ†ç±»
        print(f"  å•ç”¨é€” single_app1 æè¿°å¤ç”¨: '{cache.get_app_description('single_app1')}'")
        
        # éªŒè¯å¤šç”¨é€”ç¼“å­˜ (åªæœ‰ id=10 æœ‰æœ‰æ•ˆåˆ†ç±»)
        print(f"\n  å¤šç”¨é€” multi_app4 + title ç¼“å­˜å‘½ä¸­: {cache.is_multipurpose_title_cached('multi_app4', 'multi_app4_title')}")
        print(f"  å¤šç”¨é€” multi_app4 + title åˆ†ç±»: {cache.get_multipurpose_category('multi_app4', 'multi_app4_title')}")
        print(f"  å¤šç”¨é€” multi_app0 ç¼“å­˜å‘½ä¸­: {cache.is_multipurpose_app_cached('multi_app0')}")  # æ— title
        print(f"  å¤šç”¨é€” multi_app1 æè¿°å¤ç”¨: '{cache.get_app_description('multi_app1')}'")
        
        # ========================================
        # 3. æµ‹è¯• CacheMatcher
        # ========================================
        print("\n[3] æµ‹è¯• CacheMatcher:")
        matcher = CacheMatcher(cache)
        
        # æµ‹è¯•äº‹ä»¶åˆ—è¡¨
        test_events = [
            # å•ç”¨é€”ï¼Œæœ‰ç¼“å­˜åˆ†ç±»
            ProcessedEvent(id='e1', app='single_app4', title='any_title', is_multipurpose=False,
                          start_time='2025-12-31 09:00:00', end_time='2025-12-31 09:05:00', duration=300),
            # å•ç”¨é€”ï¼Œæ— ç¼“å­˜åˆ†ç±»
            ProcessedEvent(id='e2', app='single_app1', title='any_title', is_multipurpose=False,
                          start_time='2025-12-31 09:05:00', end_time='2025-12-31 09:10:00', duration=300),
            # å•ç”¨é€”ï¼Œå®Œå…¨æ–°åº”ç”¨
            ProcessedEvent(id='e3', app='new_single_app', title='new_title', is_multipurpose=False,
                          start_time='2025-12-31 09:10:00', end_time='2025-12-31 09:15:00', duration=300),
            # å¤šç”¨é€”ï¼Œæœ‰ç¼“å­˜åˆ†ç±»
            ProcessedEvent(id='e4', app='multi_app4', title='multi_app4_title', is_multipurpose=True,
                          start_time='2025-12-31 09:15:00', end_time='2025-12-31 09:20:00', duration=300),
            # å¤šç”¨é€”ï¼Œappåœ¨ç¼“å­˜ä½†titleä¸åœ¨
            ProcessedEvent(id='e5', app='multi_app4', title='new_title_for_multi_app4', is_multipurpose=True,
                          start_time='2025-12-31 09:20:00', end_time='2025-12-31 09:25:00', duration=300),
            # å¤šç”¨é€”ï¼Œå®Œå…¨æ–°åº”ç”¨
            ProcessedEvent(id='e6', app='new_multi_app', title='new_multi_title', is_multipurpose=True,
                          start_time='2025-12-31 09:25:00', end_time='2025-12-31 09:30:00', duration=300),
        ]
        
        for event in test_events:
            matcher.match(event)
            status = "HIT" if event.cache_matched else "MISS"
            print(f"  [{status}] {event.app} | title={event.title[:25]}... | cat={event.category_id}")
        
        print(f"\n  åŒ¹é…ç»Ÿè®¡: {matcher.get_stats()}")
        
        # ========================================
        # 4. æµ‹è¯• ClassifyCollector
        # ========================================
        print("\n[4] æµ‹è¯• ClassifyCollector:")
        collector = ClassifyCollector(cache)
        
        for event in test_events:
            collector.collect(event)
        
        state = collector.build_state()
        print(f"  æ”¶é›†ç»Ÿè®¡: {collector.get_stats()}")
        print(f"  å¾…åˆ†ç±»åº”ç”¨: {list(state.app_registry.keys())}")
        print(f"  å¾…åˆ†ç±»æ—¥å¿—é¡¹æ•°: {len(state.log_items)}")
        
        print("\n  å¾…åˆ†ç±»æ—¥å¿—é¡¹è¯¦æƒ…:")
        for item in state.log_items:
            app_info = state.app_registry.get(item.app)
            multi_str = "å¤šç”¨é€”" if app_info and app_info.is_multipurpose else "å•ç”¨é€”"
            desc = app_info.description if app_info else ""
            print(f"    id={item.id} | {multi_str} | app={item.app} | title={item.title} | desc='{desc}'")
        
        print("\n" + "="*70)
        print("æµ‹è¯•å®Œæˆ!")
        print("="*70)
    
    # è¿è¡Œæµ‹è¯•
    test_v1_and_v2()
    # special_test()