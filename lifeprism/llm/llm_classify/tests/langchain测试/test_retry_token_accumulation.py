"""
æµ‹è¯• LangGraph RetryPolicy çš„ Token ç´¯åŠ è¡Œä¸º

æ ¸å¿ƒé—®é¢˜ï¼š
- å½“èŠ‚ç‚¹æ‰§è¡Œè¿‡ç¨‹ä¸­æŠ›å‡ºå¼‚å¸¸ï¼ŒRetryPolicy ä¼šå›æ»š State
- é—®é¢˜æ˜¯ï¼šèŠ‚ç‚¹å†…éƒ¨"æ¶ˆè€—"çš„ tokens æ˜¯å¦ä¼šè¢«ç´¯åŠ åˆ°ä¸» Stateï¼Ÿ

æµ‹è¯•åœºæ™¯ï¼š
1. èŠ‚ç‚¹æ‰§è¡Œå¹¶æ¨¡æ‹Ÿ token æ¶ˆè€—
2. èŠ‚ç‚¹è¿”å› token ä½¿ç”¨è®°å½•
3. èŠ‚ç‚¹æŠ›å‡ºå¼‚å¸¸ -> è§¦å‘é‡è¯•
4. æœ€ç»ˆéªŒè¯ï¼štoken æ˜¯å¦è¢«ç´¯åŠ äº†å¤šæ¬¡
"""

from typing import Annotated
import operator
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langgraph.types import RetryPolicy


class TestState(BaseModel):
    """æµ‹è¯•ç”¨çš„ State - ä½¿ç”¨ Pydantic æ¨¡å‹"""
    attempt_count: int = 0  # å°è¯•æ¬¡æ•°
    # ä½¿ç”¨ operator.or_ åˆå¹¶ dictï¼Œæ¨¡æ‹Ÿé¡¹ç›®ä¸­çš„ node_token_usage
    node_token_usage: Annotated[dict[str, dict], operator.or_] = Field(default_factory=dict)
    # ä½¿ç”¨ operator.add ç´¯åŠ  listï¼Œæµ‹è¯•åˆ—è¡¨ç´¯åŠ è¡Œä¸º
    token_list: Annotated[list[dict], operator.add] = Field(default_factory=list)
    result: str = ""


# å…¨å±€è®¡æ•°å™¨ï¼Œç”¨äºè·Ÿè¸ªå®é™…æ‰§è¡Œæ¬¡æ•°
execution_count = 0


def failing_node_returns_before_exception(state: TestState) -> dict:
    """
    æµ‹è¯•åœºæ™¯ 1ï¼šèŠ‚ç‚¹è¿”å›åå†æŠ›å¼‚å¸¸
    
    æ³¨æ„ï¼šPython ä¸­ return åçš„ä»£ç ä¸ä¼šæ‰§è¡Œï¼Œ
    ä½†è¿™é‡Œæµ‹è¯•çš„æ˜¯ LangGraph å¯¹èŠ‚ç‚¹è¿”å›å€¼çš„å¤„ç†
    """
    global execution_count
    execution_count += 1
    
    print(f"\n{'='*60}")
    print(f"[failing_node] æ‰§è¡Œæ¬¡æ•°: {execution_count}")
    print(f"å½“å‰ State.node_token_usage: {state.node_token_usage}")
    print(f"å½“å‰ State.token_list: {state.token_list}")
    print(f"{'='*60}")
    
    # æ¨¡æ‹Ÿæ¯æ¬¡è°ƒç”¨éƒ½æ¶ˆè€— token
    current_tokens = {
        'input_tokens': 100 * execution_count,  # æ¯æ¬¡ä¸åŒï¼Œä¾¿äºåŒºåˆ†
        'output_tokens': 50 * execution_count,
        'total_tokens': 150 * execution_count
    }
    
    print(f"   æœ¬æ¬¡ token æ¶ˆè€—: {current_tokens}")
    
    # å‰ä¸¤æ¬¡æŠ›å‡ºå¼‚å¸¸
    if execution_count < 3:
        print(f"âš ï¸  ç¬¬ {execution_count} æ¬¡æ‰§è¡Œï¼šå‡†å¤‡æŠ›å‡ºå¼‚å¸¸...")
        # å…³é”®ç‚¹ï¼šè¿™é‡ŒæŠ›å‡ºå¼‚å¸¸ï¼ŒèŠ‚ç‚¹ä¸ä¼šæ­£å¸¸è¿”å›
        # RetryPolicy åº”è¯¥å›æ»š State åˆ°èŠ‚ç‚¹æ‰§è¡Œå‰çš„çŠ¶æ€
        raise ValueError(f"æ¨¡æ‹Ÿç¬¬ {execution_count} æ¬¡å¤±è´¥")
    
    # ç¬¬ä¸‰æ¬¡æˆåŠŸ
    print(f"âœ… ç¬¬ {execution_count} æ¬¡æ‰§è¡Œï¼šæˆåŠŸï¼")
    
    return {
        "attempt_count": execution_count,
        "node_token_usage": {"failing_node": current_tokens},
        "token_list": [current_tokens],
        "result": f"æˆåŠŸäºç¬¬ {execution_count} æ¬¡å°è¯•"
    }


def test_with_tokens_before_exception():
    """
    æµ‹è¯•åœºæ™¯ 2ï¼šåœ¨æŠ›å¼‚å¸¸ä¹‹å‰å…ˆä¿®æ”¹ stateï¼ˆé€šè¿‡è¿”å› dictï¼‰
    
    ä½†æ˜¯ Python ä¸­ï¼Œä¸€æ—¦ raise å¼‚å¸¸ï¼Œreturn è¯­å¥ä¸ä¼šæ‰§è¡Œã€‚
    æ‰€ä»¥éœ€è¦ç”¨ä¸€ä¸ªåŒ…è£…å™¨æ¥æµ‹è¯•"å¦‚æœèŠ‚ç‚¹è¿”å›äº†å€¼ç„¶åæŸå¤„å‡ºé”™"çš„æƒ…å†µ
    """
    pass


class TokenTracker:
    """ç”¨äºè·Ÿè¸ª token æ¶ˆè€—çš„å…¨å±€å¯¹è±¡"""
    def __init__(self):
        self.total_tokens_consumed = 0
        self.call_history = []
    
    def consume(self, tokens: int, attempt: int):
        """æ¨¡æ‹Ÿæ¶ˆè€— tokens"""
        self.total_tokens_consumed += tokens
        self.call_history.append({
            'attempt': attempt,
            'tokens': tokens,
            'cumulative': self.total_tokens_consumed
        })
        print(f"ğŸ“Š TokenTracker: ç¬¬ {attempt} æ¬¡æ¶ˆè€— {tokens} tokensï¼Œç´¯è®¡: {self.total_tokens_consumed}")


# å…¨å±€ token tracker
token_tracker = TokenTracker()


def node_with_external_side_effect(state: TestState) -> dict:
    """
    æµ‹è¯•èŠ‚ç‚¹ï¼šæ¨¡æ‹Ÿå¤–éƒ¨å‰¯ä½œç”¨ï¼ˆå¦‚ API è°ƒç”¨ï¼‰
    
    å…³é”®é—®é¢˜ï¼šå³ä½¿ LangGraph å›æ»š Stateï¼Œå¤–éƒ¨å‰¯ä½œç”¨ï¼ˆå¦‚ API è°ƒç”¨ï¼‰ä»ç„¶å‘ç”Ÿäº†
    è¿™ä¸ªæµ‹è¯•æ¼”ç¤ºï¼štoken æ¶ˆè€—æ˜¯ "å¤–éƒ¨å‰¯ä½œç”¨"ï¼Œä¸å— State å›æ»šå½±å“
    """
    global execution_count
    execution_count += 1
    
    print(f"\n{'='*60}")
    print(f"[side_effect_node] æ‰§è¡Œæ¬¡æ•°: {execution_count}")
    print(f"{'='*60}")
    
    # æ¨¡æ‹Ÿ API è°ƒç”¨æ¶ˆè€— tokenï¼ˆè¿™æ˜¯çœŸå®çš„å¤–éƒ¨å‰¯ä½œç”¨ï¼‰
    tokens_this_call = 100
    token_tracker.consume(tokens_this_call, execution_count)
    
    if execution_count < 3:
        print(f"âš ï¸  æŠ›å‡ºå¼‚å¸¸ï¼Œä½† token å·²ç»è¢« API æ¶ˆè€—äº†ï¼")
        raise ValueError(f"æ¨¡æ‹Ÿç¬¬ {execution_count} æ¬¡å¤±è´¥")
    
    print(f"âœ… æˆåŠŸï¼")
    
    return {
        "attempt_count": execution_count,
        "node_token_usage": {
            "side_effect_node": {
                'input_tokens': tokens_this_call,
                'output_tokens': 50,
                'total_tokens': tokens_this_call + 50
            }
        },
        "result": "æˆåŠŸ"
    }


def run_test_1():
    """æµ‹è¯• 1ï¼šéªŒè¯ RetryPolicy çš„ State å›æ»šè¡Œä¸º"""
    global execution_count
    execution_count = 0
    
    print("\n" + "="*70)
    print("æµ‹è¯• 1: éªŒè¯ RetryPolicy çš„ State å›æ»šè¡Œä¸º")
    print("="*70)
    
    graph = StateGraph(TestState)
    graph.add_node(
        "failing_node",
        failing_node_returns_before_exception,
        retry_policy=RetryPolicy(max_attempts=3, retry_on=ValueError)
    )
    graph.add_edge(START, "failing_node")
    graph.add_edge("failing_node", END)
    
    app = graph.compile()
    
    initial_state = TestState()
    print(f"åˆå§‹ State: {initial_state.model_dump()}")
    
    try:
        final_state = app.invoke(initial_state.model_dump())
        
        print("\n" + "="*70)
        print("æµ‹è¯• 1 ç»“æœ:")
        print("="*70)
        print(f"æœ€ç»ˆ node_token_usage: {final_state.get('node_token_usage')}")
        print(f"æœ€ç»ˆ token_list: {final_state.get('token_list')}")
        print(f"å®é™…æ‰§è¡Œæ¬¡æ•°: {execution_count}")
        
        # éªŒè¯
        token_usage = final_state.get('node_token_usage', {})
        token_list = final_state.get('token_list', [])
        
        print("\nğŸ“‹ åˆ†æ:")
        if token_usage:
            failing_node_tokens = token_usage.get('failing_node', {})
            expected_total = 150 * 3  # ç¬¬ 3 æ¬¡æˆåŠŸ
            actual_total = failing_node_tokens.get('total_tokens', 0)
            
            print(f"   node_token_usage ä¸­çš„ total_tokens: {actual_total}")
            if actual_total == expected_total:
                print(f"   âœ… åªè®°å½•äº†æœ€åä¸€æ¬¡æˆåŠŸçš„ token æ¶ˆè€— ({expected_total})")
            else:
                print(f"   âš ï¸  token æ¶ˆè€—å€¼å¼‚å¸¸: æœŸæœ› {expected_total}, å®é™… {actual_total}")
        
        if token_list:
            print(f"   token_list é•¿åº¦: {len(token_list)}")
            if len(token_list) == 1:
                print("   âœ… token_list åªåŒ…å«æœ€åä¸€æ¬¡æˆåŠŸçš„è®°å½•")
            else:
                print(f"   âŒ token_list åŒ…å«äº†å¤šæ¬¡å°è¯•çš„è®°å½•: {token_list}")
        
        return final_state
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        return None


def run_test_2():
    """æµ‹è¯• 2ï¼šéªŒè¯å¤–éƒ¨å‰¯ä½œç”¨ä¸å— State å›æ»šå½±å“"""
    global execution_count
    execution_count = 0
    token_tracker.total_tokens_consumed = 0
    token_tracker.call_history = []
    
    print("\n" + "="*70)
    print("æµ‹è¯• 2: éªŒè¯å¤–éƒ¨å‰¯ä½œç”¨ï¼ˆAPI è°ƒç”¨ï¼‰ä¸å— State å›æ»šå½±å“")
    print("="*70)
    
    graph = StateGraph(TestState)
    graph.add_node(
        "side_effect_node",
        node_with_external_side_effect,
        retry_policy=RetryPolicy(max_attempts=3, retry_on=ValueError)
    )
    graph.add_edge(START, "side_effect_node")
    graph.add_edge("side_effect_node", END)
    
    app = graph.compile()
    
    initial_state = TestState()
    
    try:
        final_state = app.invoke(initial_state.model_dump())
        
        print("\n" + "="*70)
        print("æµ‹è¯• 2 ç»“æœ:")
        print("="*70)
        print(f"æœ€ç»ˆ State.node_token_usage: {final_state.get('node_token_usage')}")
        print(f"\nğŸ“Š TokenTracker (å¤–éƒ¨å‰¯ä½œç”¨):")
        print(f"   å®é™… API è°ƒç”¨æ¬¡æ•°: {len(token_tracker.call_history)}")
        print(f"   ç´¯è®¡æ¶ˆè€—çš„ tokens: {token_tracker.total_tokens_consumed}")
        print(f"   è°ƒç”¨å†å²: {token_tracker.call_history}")
        
        print("\nğŸ“‹ å…³é”®ç»“è®º:")
        state_tokens = final_state.get('node_token_usage', {}).get('side_effect_node', {}).get('input_tokens', 0)
        print(f"   1. State ä¸­è®°å½•çš„ input_tokens: {state_tokens}")
        print(f"   2. å®é™… API æ¶ˆè€—çš„ tokens: {token_tracker.total_tokens_consumed}")
        
        if token_tracker.total_tokens_consumed > state_tokens:
            print(f"\n   âš ï¸  é‡è¦å‘ç°:")
            print(f"      - State åªè®°å½•äº†æœ€åä¸€æ¬¡æˆåŠŸçš„ token ({state_tokens})")
            print(f"      - ä½†å®é™… API è°ƒç”¨æ¶ˆè€—äº† {token_tracker.total_tokens_consumed} tokensï¼")
            print(f"      - å·®å€¼ = {token_tracker.total_tokens_consumed - state_tokens} (è¿™æ˜¯é‡è¯•é€ æˆçš„é¢å¤–æ¶ˆè€—)")
        
        return final_state
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        return None


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸ”¬"*35)
    print(" LangGraph RetryPolicy Token ç´¯åŠ è¡Œä¸ºæµ‹è¯•")
    print("ğŸ”¬"*35)
    
    # æµ‹è¯• 1
    result1 = run_test_1()
    
    # æµ‹è¯• 2  
    result2 = run_test_2()
    
    # æ€»ç»“
    print("\n" + "="*70)
    print("ğŸ“ æ€»ç»“")
    print("="*70)
    print("""
ç»“è®ºï¼š
1. å½“èŠ‚ç‚¹æŠ›å‡ºå¼‚å¸¸æ—¶ï¼ŒLangGraph ä¼šå›æ»š State åˆ°èŠ‚ç‚¹æ‰§è¡Œå‰çš„çŠ¶æ€
2. å› æ­¤ï¼Œå¤±è´¥çš„èŠ‚ç‚¹è¿”å›å€¼ï¼ˆåŒ…æ‹¬ token_usageï¼‰ä¸ä¼šè¢«åº”ç”¨åˆ° State
3. åªæœ‰æœ€åä¸€æ¬¡æˆåŠŸæ‰§è¡Œçš„è¿”å›å€¼ä¼šè¢«åº”ç”¨

ä½†æ˜¯æ³¨æ„ï¼š
- State å›æ»š â‰  API è°ƒç”¨è¢«æ’¤é”€
- å³ä½¿ State è¢«å›æ»šï¼Œå®é™…çš„ LLM API è°ƒç”¨å·²ç»å‘ç”Ÿ
- Token å·²ç»è¢« API æ¶ˆè€—äº†ï¼Œè¿™æ˜¯æ— æ³•å›æ»šçš„å¤–éƒ¨å‰¯ä½œç”¨
- å› æ­¤ï¼Œå¦‚æœéœ€è¦å‡†ç¡®ç»Ÿè®¡ API æ¶ˆè€—ï¼Œéœ€è¦åœ¨å¤–éƒ¨è¿›è¡Œè¿½è¸ª
""")


# ============================================================
# æµ‹è¯• 3ï¼šéªŒè¯ Send å¹¶å‘åœºæ™¯ä¸‹å…¨å±€ list append çš„å®‰å…¨æ€§
# ============================================================

from langgraph.types import Send
import time
import random

# å…¨å±€ token ç´¯åŠ åˆ—è¡¨
global_token_list = []


class SendTestState(BaseModel):
    """Send æµ‹è¯•ç”¨çš„ State"""
    items: list[int] = Field(default_factory=list)  # è¦å¹¶å‘å¤„ç†çš„ items
    results: Annotated[list[dict], operator.add] = Field(default_factory=list)


def generate_items(state: SendTestState) -> dict:
    """ç”Ÿæˆè¦å¹¶å‘å¤„ç†çš„ items"""
    return {"items": list(range(10))}  # ç”Ÿæˆ 10 ä¸ª item


def send_to_workers(state: SendTestState) -> list[Send]:
    """Fan out: ä¸ºæ¯ä¸ª item åˆ›å»ºä¸€ä¸ªå¹¶å‘ä»»åŠ¡"""
    print(f"\nğŸ“¤ Sending {len(state.items)} items to workers...")
    return [Send("worker_node", {"item_id": i}) for i in state.items]


def worker_node(state: dict) -> dict:
    """
    å¹¶å‘ worker èŠ‚ç‚¹
    æ¯ä¸ª worker ç‹¬ç«‹æ‰§è¡Œï¼Œå¹¶å‘å…¨å±€ list è¿½åŠ  token è®°å½•
    """
    global global_token_list
    
    item_id = state.get("item_id", -1)
    
    # æ¨¡æ‹Ÿä¸€äº›å¤„ç†æ—¶é—´ (0-50ms)
    delay = random.uniform(0, 0.05)
    time.sleep(delay)
    
    # æ¨¡æ‹Ÿ token æ¶ˆè€—
    token_usage = {
        "worker_id": item_id,
        "input_tokens": 100 + item_id * 10,
        "output_tokens": 50 + item_id * 5,
        "timestamp": time.time()
    }
    
    # å…³é”®æ“ä½œï¼šå‘å…¨å±€ list append
    global_token_list.append(token_usage)
    
    print(f"   Worker {item_id} å®Œæˆ, tokens: {token_usage['input_tokens']}")
    
    return {"results": [{"item_id": item_id, "status": "done"}]}


def collect_results(state: SendTestState) -> dict:
    """æ”¶é›†æ‰€æœ‰ worker çš„ç»“æœ"""
    print(f"\nğŸ“¥ æ”¶é›†ç»“æœ: {len(state.results)} ä¸ª worker å®Œæˆ")
    return {}


def run_test_3():
    """æµ‹è¯• 3ï¼šéªŒè¯ Send å¹¶å‘åœºæ™¯ä¸‹å…¨å±€ list append çš„å®‰å…¨æ€§"""
    global global_token_list
    global_token_list = []  # é‡ç½®
    
    print("\n" + "="*70)
    print("æµ‹è¯• 3: éªŒè¯ Send å¹¶å‘åœºæ™¯ä¸‹å…¨å±€ list append çš„å®‰å…¨æ€§")
    print("="*70)
    
    graph = StateGraph(SendTestState)
    
    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("generate", generate_items)
    graph.add_node("worker_node", worker_node)
    graph.add_node("collect", collect_results)
    
    # æ·»åŠ è¾¹
    graph.add_edge(START, "generate")
    graph.add_conditional_edges("generate", send_to_workers, ["worker_node"])
    graph.add_edge("worker_node", "collect")
    graph.add_edge("collect", END)
    
    app = graph.compile()
    
    initial_state = SendTestState()
    
    try:
        final_state = app.invoke(initial_state.model_dump())
        
        print("\n" + "="*70)
        print("æµ‹è¯• 3 ç»“æœ:")
        print("="*70)
        
        # éªŒè¯ç»“æœ
        expected_count = 10  # æˆ‘ä»¬å‘é€äº† 10 ä¸ª items
        actual_count = len(global_token_list)
        
        print(f"æœŸæœ› worker æ•°é‡: {expected_count}")
        print(f"å…¨å±€ list ä¸­çš„è®°å½•æ•°: {actual_count}")
        print(f"State.results é•¿åº¦: {len(final_state.get('results', []))}")
        
        # éªŒè¯æ‰€æœ‰ worker_id éƒ½è¢«è®°å½•
        recorded_ids = set(item.get("worker_id") for item in global_token_list)
        expected_ids = set(range(10))
        
        print(f"\nè®°å½•çš„ worker IDs: {sorted(recorded_ids)}")
        print(f"æœŸæœ›çš„ worker IDs: {sorted(expected_ids)}")
        
        if recorded_ids == expected_ids and actual_count == expected_count:
            print("\nâœ… æµ‹è¯•é€šè¿‡ï¼å…¨å±€ list append åœ¨ Send å¹¶å‘åœºæ™¯ä¸‹æ˜¯å®‰å…¨çš„ï¼")
            print(f"   - æ‰€æœ‰ {expected_count} ä¸ª worker çš„ token éƒ½è¢«æ­£ç¡®è®°å½•")
            print(f"   - æ²¡æœ‰ä¸¢å¤±æ•°æ®")
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼")
            if actual_count != expected_count:
                print(f"   - æ•°æ®ä¸¢å¤±: æœŸæœ› {expected_count}, å®é™… {actual_count}")
            if recorded_ids != expected_ids:
                missing = expected_ids - recorded_ids
                extra = recorded_ids - expected_ids
                if missing:
                    print(f"   - ç¼ºå¤±çš„ IDs: {missing}")
                if extra:
                    print(f"   - é¢å¤–çš„ IDs: {extra}")
        
        # æ‰“å° token ç»Ÿè®¡
        total_input = sum(item.get("input_tokens", 0) for item in global_token_list)
        total_output = sum(item.get("output_tokens", 0) for item in global_token_list)
        print(f"\nğŸ“Š Token ç»Ÿè®¡:")
        print(f"   æ€» input_tokens: {total_input}")
        print(f"   æ€» output_tokens: {total_output}")
        print(f"   æ€» tokens: {total_input + total_output}")
        
        return final_state
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸ”¬"*35)
    print(" LangGraph RetryPolicy Token ç´¯åŠ è¡Œä¸ºæµ‹è¯•")
    print("ğŸ”¬"*35)
    
    # æµ‹è¯• 1
    result1 = run_test_1()
    
    # æµ‹è¯• 2  
    result2 = run_test_2()
    
    # æµ‹è¯• 3: Send å¹¶å‘æµ‹è¯•
    result3 = run_test_3()
    
    # æ€»ç»“
    print("\n" + "="*70)
    print("ğŸ“ æ€»ç»“")
    print("="*70)
    print("""
ç»“è®ºï¼š
1. å½“èŠ‚ç‚¹æŠ›å‡ºå¼‚å¸¸æ—¶ï¼ŒLangGraph ä¼šå›æ»š State åˆ°èŠ‚ç‚¹æ‰§è¡Œå‰çš„çŠ¶æ€
2. å› æ­¤ï¼Œå¤±è´¥çš„èŠ‚ç‚¹è¿”å›å€¼ï¼ˆåŒ…æ‹¬ token_usageï¼‰ä¸ä¼šè¢«åº”ç”¨åˆ° State
3. åªæœ‰æœ€åä¸€æ¬¡æˆåŠŸæ‰§è¡Œçš„è¿”å›å€¼ä¼šè¢«åº”ç”¨

ä½†æ˜¯æ³¨æ„ï¼š
- State å›æ»š â‰  API è°ƒç”¨è¢«æ’¤é”€
- å³ä½¿ State è¢«å›æ»šï¼Œå®é™…çš„ LLM API è°ƒç”¨å·²ç»å‘ç”Ÿ
- Token å·²ç»è¢« API æ¶ˆè€—äº†ï¼Œè¿™æ˜¯æ— æ³•å›æ»šçš„å¤–éƒ¨å‰¯ä½œç”¨
- å› æ­¤ï¼Œå¦‚æœéœ€è¦å‡†ç¡®ç»Ÿè®¡ API æ¶ˆè€—ï¼Œéœ€è¦åœ¨å¤–éƒ¨è¿›è¡Œè¿½è¸ª

æµ‹è¯• 3 ç»“è®ºï¼š
- åœ¨ LangGraph çš„ Send å¹¶å‘åœºæ™¯ä¸‹ï¼Œå…¨å±€ list.append() æ˜¯å®‰å…¨çš„
- å› ä¸º LangGraph ä½¿ç”¨ asyncio åç¨‹ï¼Œè€Œéå¤šçº¿ç¨‹
- æ‰€æœ‰å¹¶å‘ worker çš„ token éƒ½èƒ½è¢«æ­£ç¡®è®°å½•
""")


if __name__ == "__main__":
    main()
